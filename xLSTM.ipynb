{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xlstm in /trinity/home/team08/workspace/.local/lib/python3.10/site-packages (1.0.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use(\"seaborn-pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \".../data/train_data/\"\n",
    "TEST_DATA_PATH = \".../data/test_data/\"\n",
    "\n",
    "TRAIN_TARGET_PATH = \".../data/train_target.csv\"\n",
    "TEST_TARGET_PATH = \".../data/test_target.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  flag\n",
       "0              0     0\n",
       "1              1     0\n",
       "2              2     0\n",
       "3              3     0\n",
       "4              4     0\n",
       "...          ...   ...\n",
       "2999995  2999995     0\n",
       "2999996  2999996     0\n",
       "2999997  2999997     0\n",
       "2999998  2999998     0\n",
       "2999999  2999999     0\n",
       "\n",
       "[3000000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(TRAIN_TARGET_PATH)\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>3499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>3499996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>3499997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>3499998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>3499999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id\n",
       "0       3000000\n",
       "1       3000001\n",
       "2       3000002\n",
       "3       3000003\n",
       "4       3000004\n",
       "...         ...\n",
       "499995  3499995\n",
       "499996  3499996\n",
       "499997  3499997\n",
       "499998  3499998\n",
       "499999  3499999\n",
       "\n",
       "[500000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target = pd.read_csv(TEST_TARGET_PATH)\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from typing import List\n",
    "\n",
    "from dataset_preprocessing_utils import features, transform_credits_to_sequences, create_padded_buckets\n",
    "\n",
    "\n",
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0, num_parts_to_read: int = 2, \n",
    "                                    columns: List[str] = None, verbose: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает ``num_parts_to_read`` партиций и преобразует их к pandas.DataFrame.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    path_to_dataset: str\n",
    "        Путь до директории с партициями.\n",
    "    start_from: int, default=0\n",
    "        Номер партиции, с которой начать чтение.\n",
    "    num_parts_to_read: int, default=2\n",
    "        Число партиций, которые требуется прочитать.\n",
    "    columns: List[str], default=None\n",
    "        Список колонок, которые нужно прочитать из каждой партиции. Если None, то считываются все колонки.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    frame: pandas.DataFrame\n",
    "        Прочитанные партиции, преобразованные к pandas.DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    start_from = max(0, start_from)\n",
    "    # dictionory of format {partition number: partition filename}\n",
    "    dataset_paths = {int(os.path.splitext(filename)[0].split(\"_\")[-1]): os.path.join(path_to_dataset, filename)\n",
    "                     for filename in os.listdir(path_to_dataset) if filename != \".ipynb_checkpoints\"}\n",
    "    chunks = [dataset_paths[num] for num in sorted(dataset_paths.keys()) if num>=start_from][:num_parts_to_read]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Reading chunks:\", *chunks, sep=\"\\n\")\n",
    "    for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path, columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В дальнейшем понадобятся следующие статистики по тренировочной и тестовой выборкам: распределение длин кредитных историй и число уникальных значений каждого категориального значения. Посчитаем эти статистики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_0.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_1.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_2.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_3.pq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/1125037625.py:40: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692edac349214fa2861d0acc3ae928f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data:  33%|███▎      | 1/3 [00:04<00:08,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_4.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_5.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_6.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_7.pq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/1125037625.py:40: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5f42514a504929a942716eed89c28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data:  67%|██████▋   | 2/3 [00:07<00:03,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_8.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_9.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_10.pq\n",
      "/trinity/home/team08/workspace/data/train_data/train_data_11.pq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/1125037625.py:40: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db317faf9d649eba11437dd2094c82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data: 100%|██████████| 3/3 [00:12<00:00,  4.07s/it]\n",
      "Count statistics on test data:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/data/test_data/test_data_0.pq\n",
      "/trinity/home/team08/workspace/data/test_data/test_data_1.pq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/1125037625.py:40: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24adb1d968754cb483f23045d94e34ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on test data: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 s, sys: 15.2 s, total: 47.7 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "train_lens = []\n",
    "test_lens = []\n",
    "uniques = defaultdict(set)\n",
    "\n",
    "for step in tqdm.tqdm(range(0, 12, 4),\n",
    "                     desc=\"Count statistics on train data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(TRAIN_DATA_PATH, step, 4, verbose=True)\n",
    "        seq_lens = credits_frame.groupby(\"id\").agg(seq_len=(\"rn\", \"max\"))[\"seq_len\"].values\n",
    "        train_lens.extend(seq_lens)\n",
    "        credits_frame.drop(columns=[\"id\", \"rn\"], inplace=True)\n",
    "        for feat in credits_frame.columns.values:\n",
    "            uniques[feat] = uniques[feat].union(credits_frame[feat].unique())\n",
    "train_lens = np.hstack(train_lens)\n",
    "\n",
    "for step in tqdm.tqdm(range(0, 2, 2),\n",
    "                     desc=\"Count statistics on test data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(TEST_DATA_PATH, step, 2, verbose=True)\n",
    "        seq_lens = credits_frame.groupby(\"id\").agg(seq_len=(\"rn\", \"max\"))[\"seq_len\"].values\n",
    "        test_lens.extend(seq_lens)\n",
    "        credits_frame.drop(columns=[\"id\", \"rn\"], inplace=True)\n",
    "        for feat in credits_frame.columns.values:\n",
    "            uniques[feat] = uniques[feat].union(credits_frame[feat].unique())\n",
    "test_lens = np.hstack(test_lens)\n",
    "uniques = dict(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Чтобы сразу убедиться, что посчитанные статистики интересные и полезные, построим графики распределений длин кредитных историй в тренировочной и тестовой выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "train_len_counter = pd.Series(Counter(train_lens)).sort_index()\n",
    "test_len_counter = pd.Series(Counter(test_lens)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 54 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), nrows=1)\n",
    "ax.bar(train_len_counter.index.values, train_len_counter.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 50 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), nrows=1)\n",
    "ax.bar(test_len_counter.index.values, test_len_counter.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 57)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lens.max(), test_lens.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Один из аргументов в функции `dataset_preprocessing_utils.create_padded_buckets` &ndash; `bucket_info` &ndash; словарь, где для конкретной длины последовательности указано до какой длины нужно делать паддинг. Возьмем простое разбиение на 43 бакета: \n",
    "| Длина последовательности | Длина после паддинга |\n",
    "| :-: | :-: \n",
    "| 1 &ndash; 40 | без изменений |\n",
    "| 41 &ndash; 45 | 45 |\n",
    "| 46 &ndash; 50 | 50 |\n",
    "| 51 &ndash; 58 | 58 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 11: 11,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 14,\n",
       " 15: 15,\n",
       " 16: 16,\n",
       " 17: 17,\n",
       " 18: 18,\n",
       " 19: 19,\n",
       " 20: 20,\n",
       " 21: 21,\n",
       " 22: 22,\n",
       " 23: 23,\n",
       " 24: 24,\n",
       " 25: 25,\n",
       " 26: 26,\n",
       " 27: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 30: 30,\n",
       " 31: 31,\n",
       " 32: 32,\n",
       " 33: 33,\n",
       " 34: 34,\n",
       " 35: 35,\n",
       " 36: 36,\n",
       " 37: 37,\n",
       " 38: 38,\n",
       " 39: 39,\n",
       " 40: 40,\n",
       " 41: 45,\n",
       " 42: 45,\n",
       " 43: 45,\n",
       " 44: 45,\n",
       " 45: 45,\n",
       " 46: 50,\n",
       " 47: 50,\n",
       " 48: 50,\n",
       " 49: 50,\n",
       " 50: 50,\n",
       " 51: 58,\n",
       " 52: 58,\n",
       " 53: 58,\n",
       " 54: 58,\n",
       " 55: 58,\n",
       " 56: 58,\n",
       " 57: 58,\n",
       " 58: 58}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_ = list(range(1, 59)) \n",
    "lens_ = list(range(1, 41)) + [45] * 5 + [50] * 5 + [58] * 8\n",
    "bucket_info = dict(zip(keys_, lens_))\n",
    "bucket_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Так же рассмотрим уникальные значения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: pre_since_opened, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_since_confirmed, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "Feature: pre_pterm, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "Feature: pre_fterm, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Feature: pre_till_pclose, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Feature: pre_till_fclose, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
      "Feature: pre_loans_credit_limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_loans_next_pay_summ, unique values: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Feature: pre_loans_outstanding, unique values: {1, 2, 3, 4, 5}\n",
      "Feature: pre_loans_total_overdue, unique values: {0, 1}\n",
      "Feature: pre_loans_max_overdue_sum, unique values: {0, 1, 2, 3}\n",
      "Feature: pre_loans_credit_cost_rate, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n",
      "Feature: pre_loans5, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17}\n",
      "Feature: pre_loans530, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_loans3060, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "Feature: pre_loans6090, unique values: {0, 1, 2, 3, 4, 5}\n",
      "Feature: pre_loans90, unique values: {1, 2, 3, 4, 8, 10, 11, 13, 14, 18, 19}\n",
      "Feature: is_zero_loans5, unique values: {0, 1}\n",
      "Feature: is_zero_loans530, unique values: {0, 1}\n",
      "Feature: is_zero_loans3060, unique values: {0, 1}\n",
      "Feature: is_zero_loans6090, unique values: {0, 1}\n",
      "Feature: is_zero_loans90, unique values: {0, 1}\n",
      "Feature: pre_util, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_over2limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_maxover2limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: is_zero_util, unique values: {0, 1}\n",
      "Feature: is_zero_over2limit, unique values: {0, 1}\n",
      "Feature: is_zero_maxover2limit, unique values: {0, 1}\n",
      "Feature: enc_paym_0, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_1, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_2, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_3, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_4, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_5, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_6, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_7, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_8, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_9, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_10, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_11, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_paym_12, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_13, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_14, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_15, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_16, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_17, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_18, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_19, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_20, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_paym_21, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_22, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_23, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_24, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_loans_account_holder_type, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: enc_loans_credit_status, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: enc_loans_credit_type, unique values: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Feature: enc_loans_account_cur, unique values: {0, 1, 2, 3}\n",
      "Feature: pclose_flag, unique values: {0, 1}\n",
      "Feature: fclose_flag, unique values: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "for feat, uniq in uniques.items():\n",
    "    print(f\"Feature: {feat}, unique values: {uniq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Поскольку паддинг будет производиться нулями, а категориальные признаки закодированы, начиная с 0, перед паддингом будем сдвигать все значения на 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Вся описанная выше предобработка данных реализована в виде функции `create_buckets_from_credits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets_from_credits(path_to_dataset, bucket_info, save_to_path, frame_with_ids = None, \n",
    "                                num_parts_to_preprocess_at_once: int = 1, \n",
    "                                num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm.notebook.tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Preparing credit data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, verbose=True)\n",
    "        credits_frame.loc[:, features] += 1       \n",
    "        seq = transform_credits_to_sequences(credits_frame)\n",
    "        print(\"Transforming credits to sequences is done.\")\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on=\"id\")\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = \"00\" + block_as_str\n",
    "        else:\n",
    "            block_as_str = \"0\" + block_as_str\n",
    "            \n",
    "        processed_fragment =  create_padded_buckets(seq, bucket_info=bucket_info, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f\"processed_chunk_{block_as_str}.pkl\"))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разобьем обучающие данные на тренировочную и валидационную выборки. Воспользуемся самым простым способом &ndash; для валидации случайным образом выберем 10% обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2700000, 2), (300000, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(train_target, random_state=42, test_size=0.1)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUCKETS_PATH = \"/trinity/home/team08/workspace/data/train_buckets_rnn\"\n",
    "VAL_BUCKETS_PATH = \"/trinity/home/team08/workspace/data/val_buckets_rnn\"\n",
    "TEST_BUCKETS_PATH = \"/trinity/home/team08/workspace/data/test_buckets_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for buckets_path in [TRAIN_BUCKETS_PATH, VAL_BUCKETS_PATH, TEST_BUCKETS_PATH]:\n",
    "#     !rm -rf $buckets_path\n",
    "#     !mkdir $buckets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 µs, sys: 49 µs, total: 167 µs\n",
      "Wall time: 333 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_000.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "#                             bucket_info=bucket_info,\n",
    "#                             save_to_path=TRAIN_BUCKETS_PATH,\n",
    "#                             frame_with_ids=train,\n",
    "#                             num_parts_to_preprocess_at_once=4, \n",
    "#                             num_parts_total=12, has_target=True)\n",
    "\n",
    "dataset_train = sorted([\n",
    "    os.path.join(TRAIN_BUCKETS_PATH, x) \n",
    "    for x in os.listdir(TRAIN_BUCKETS_PATH) \n",
    "    if os.path.isfile(os.path.join(TRAIN_BUCKETS_PATH, x))  # Ensure it's a file, not a directory\n",
    "])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 165 µs, sys: 0 ns, total: 165 µs\n",
      "Wall time: 244 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/trinity/home/team08/workspace/data/val_buckets_rnn/processed_chunk_000.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "#                             bucket_info=bucket_info,\n",
    "#                             save_to_path=VAL_BUCKETS_PATH,\n",
    "#                             frame_with_ids=val,\n",
    "#                             num_parts_to_preprocess_at_once=4, \n",
    "#                             num_parts_total=12, has_target=True)\n",
    "\n",
    "dataset_val = sorted([\n",
    "    os.path.join(VAL_BUCKETS_PATH, x) \n",
    "    for x in os.listdir(VAL_BUCKETS_PATH) \n",
    "    if os.path.isfile(os.path.join(VAL_BUCKETS_PATH, x))  # Ensure it's a file, not a directory\n",
    "])\n",
    "\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78 µs, sys: 32 µs, total: 110 µs\n",
      "Wall time: 148 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/trinity/home/team08/workspace/data/test_buckets_rnn/processed_chunk_000.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create_buckets_from_credits(TEST_DATA_PATH,\n",
    "#                             bucket_info=bucket_info,\n",
    "#                             save_to_path=TEST_BUCKETS_PATH, num_parts_to_preprocess_at_once=2, \n",
    "#                             num_parts_total=2)\n",
    "\n",
    "dataset_test = sorted([os.path.join(TEST_BUCKETS_PATH, x) for x in os.listdir(TEST_BUCKETS_PATH)])\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train\n",
    "\n",
    "temp_file_path = '/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_000.pkl'\n",
    "\n",
    "with open(temp_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "len(data['padded_sequences'][23][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['id'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import batches_generator\n",
    "from pytorch_training import eval_model, inference\n",
    "from training_aux import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embed_dim(n_cat: int) -> int:\n",
    "    return min(600, round(1.6 * n_cat**0.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_since_opened': (20, 9),\n",
       " 'pre_since_confirmed': (18, 8),\n",
       " 'pre_pterm': (18, 8),\n",
       " 'pre_fterm': (17, 8),\n",
       " 'pre_till_pclose': (17, 8),\n",
       " 'pre_till_fclose': (16, 8),\n",
       " 'pre_loans_credit_limit': (20, 9),\n",
       " 'pre_loans_next_pay_summ': (8, 5),\n",
       " 'pre_loans_outstanding': (6, 4),\n",
       " 'pre_loans_total_overdue': (2, 2),\n",
       " 'pre_loans_max_overdue_sum': (4, 3),\n",
       " 'pre_loans_credit_cost_rate': (14, 7),\n",
       " 'pre_loans5': (18, 8),\n",
       " 'pre_loans530': (20, 9),\n",
       " 'pre_loans3060': (10, 6),\n",
       " 'pre_loans6090': (6, 4),\n",
       " 'pre_loans90': (20, 9),\n",
       " 'is_zero_loans5': (2, 2),\n",
       " 'is_zero_loans530': (2, 2),\n",
       " 'is_zero_loans3060': (2, 2),\n",
       " 'is_zero_loans6090': (2, 2),\n",
       " 'is_zero_loans90': (2, 2),\n",
       " 'pre_util': (20, 9),\n",
       " 'pre_over2limit': (20, 9),\n",
       " 'pre_maxover2limit': (20, 9),\n",
       " 'is_zero_util': (2, 2),\n",
       " 'is_zero_over2limit': (2, 2),\n",
       " 'is_zero_maxover2limit': (2, 2),\n",
       " 'enc_paym_0': (4, 3),\n",
       " 'enc_paym_1': (4, 3),\n",
       " 'enc_paym_2': (4, 3),\n",
       " 'enc_paym_3': (4, 3),\n",
       " 'enc_paym_4': (4, 3),\n",
       " 'enc_paym_5': (4, 3),\n",
       " 'enc_paym_6': (4, 3),\n",
       " 'enc_paym_7': (4, 3),\n",
       " 'enc_paym_8': (4, 3),\n",
       " 'enc_paym_9': (4, 3),\n",
       " 'enc_paym_10': (4, 3),\n",
       " 'enc_paym_11': (5, 4),\n",
       " 'enc_paym_12': (4, 3),\n",
       " 'enc_paym_13': (4, 3),\n",
       " 'enc_paym_14': (4, 3),\n",
       " 'enc_paym_15': (4, 3),\n",
       " 'enc_paym_16': (4, 3),\n",
       " 'enc_paym_17': (4, 3),\n",
       " 'enc_paym_18': (4, 3),\n",
       " 'enc_paym_19': (4, 3),\n",
       " 'enc_paym_20': (5, 4),\n",
       " 'enc_paym_21': (4, 3),\n",
       " 'enc_paym_22': (4, 3),\n",
       " 'enc_paym_23': (4, 3),\n",
       " 'enc_paym_24': (5, 4),\n",
       " 'enc_loans_account_holder_type': (7, 5),\n",
       " 'enc_loans_credit_status': (7, 5),\n",
       " 'enc_loans_credit_type': (8, 5),\n",
       " 'enc_loans_account_cur': (4, 3),\n",
       " 'pclose_flag': (2, 2),\n",
       " 'fclose_flag': (2, 2)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_projections = {feat: (max(uniq)+1, compute_embed_dim(max(uniq)+1)) for feat, uniq in uniques.items()}\n",
    "embedding_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class CausalConv1D(nn.Module):\n",
    "     def __init__(self, in_channels, out_channels, kernel_size, dilation=1, **kwargs):\n",
    "         super(CausalConv1D, self).__init__()\n",
    "         self.padding = (kernel_size - 1) * dilation\n",
    "         self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=self.padding, dilation=dilation, **kwargs)\n",
    " \n",
    "     def forward(self, x):\n",
    "         x = self.conv(x)\n",
    "         return x[:, :, :-self.padding]\n",
    " \n",
    "class BlockDiagonal(nn.Module):\n",
    "     def __init__(self, in_features, out_features, num_blocks):\n",
    "         super(BlockDiagonal, self).__init__()\n",
    "         self.in_features = in_features\n",
    "         self.out_features = out_features\n",
    "         self.num_blocks = num_blocks\n",
    " \n",
    "         assert in_features % num_blocks == 0\n",
    "         assert out_features % num_blocks == 0\n",
    "         \n",
    "         block_in_features = in_features // num_blocks\n",
    "         block_out_features = out_features // num_blocks\n",
    "         \n",
    "         self.blocks = nn.ModuleList([\n",
    "             nn.Linear(block_in_features, block_out_features)\n",
    "             for _ in range(num_blocks)\n",
    "         ])\n",
    "         \n",
    "     def forward(self, x):\n",
    "         x = x.chunk(self.num_blocks, dim=-1)\n",
    "         x = [block(x_i) for block, x_i in zip(self.blocks, x)]\n",
    "         x = torch.cat(x, dim=-1)\n",
    "         return x\n",
    " \n",
    "class sLSTMBlock(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_heads, proj_factor=4/3):\n",
    "         super(sLSTMBlock, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.hidden_size = hidden_size\n",
    "         self.num_heads = num_heads\n",
    "         self.head_size = hidden_size // num_heads\n",
    "         self.proj_factor = proj_factor\n",
    " \n",
    "         assert hidden_size % num_heads == 0\n",
    "         assert proj_factor > 0\n",
    " \n",
    "         self.layer_norm = nn.LayerNorm(input_size)\n",
    "         self.causal_conv = CausalConv1D(1, 1, 4)\n",
    " \n",
    "         self.Wz = BlockDiagonal(input_size, hidden_size, num_heads)\n",
    "         self.Wi = BlockDiagonal(input_size, hidden_size, num_heads)\n",
    "         self.Wf = BlockDiagonal(input_size, hidden_size, num_heads)\n",
    "         self.Wo = BlockDiagonal(input_size, hidden_size, num_heads)\n",
    " \n",
    "         self.Rz = BlockDiagonal(hidden_size, hidden_size, num_heads)\n",
    "         self.Ri = BlockDiagonal(hidden_size, hidden_size, num_heads)\n",
    "         self.Rf = BlockDiagonal(hidden_size, hidden_size, num_heads)\n",
    "         self.Ro = BlockDiagonal(hidden_size, hidden_size, num_heads)\n",
    " \n",
    "         self.group_norm = nn.GroupNorm(num_heads, hidden_size)\n",
    " \n",
    "         self.up_proj_left = nn.Linear(hidden_size, int(hidden_size * proj_factor))\n",
    "         self.up_proj_right = nn.Linear(hidden_size, int(hidden_size * proj_factor))\n",
    "         self.down_proj = nn.Linear(int(hidden_size * proj_factor), input_size)\n",
    " \n",
    "     def forward(self, x, prev_state):\n",
    "         assert x.size(-1) == self.input_size\n",
    "         h_prev, c_prev, n_prev, m_prev = prev_state\n",
    "         x_norm = self.layer_norm(x)\n",
    "         x_conv = F.silu(self.causal_conv(x_norm.unsqueeze(1)).squeeze(1))\n",
    " \n",
    "         z = torch.tanh(self.Wz(x) + self.Rz(h_prev))\n",
    "         o = torch.sigmoid(self.Wo(x) + self.Ro(h_prev))\n",
    "         i_tilde = self.Wi(x_conv) + self.Ri(h_prev)\n",
    "         f_tilde = self.Wf(x_conv) + self.Rf(h_prev)\n",
    " \n",
    "         m_t = torch.max(f_tilde + m_prev, i_tilde)\n",
    "         i = torch.exp(i_tilde - m_t)\n",
    "         f = torch.exp(f_tilde + m_prev - m_t)\n",
    " \n",
    "         c_t = f * c_prev + i * z\n",
    "         n_t = f * n_prev + i\n",
    "         h_t = o * c_t / n_t\n",
    " \n",
    "         output = h_t\n",
    "         output_norm = self.group_norm(output)\n",
    "         output_left = self.up_proj_left(output_norm)\n",
    "         output_right = self.up_proj_right(output_norm)\n",
    "         output_gated = F.gelu(output_right)\n",
    "         output = output_left * output_gated\n",
    "         output = self.down_proj(output)\n",
    "         final_output = output + x\n",
    " \n",
    "         return final_output, (h_t, c_t, n_t, m_t)\n",
    "     \n",
    "class sLSTM(nn.Module):\n",
    "     # TODO: Add bias, dropout, bidirectional\n",
    "     def __init__(self, input_size, hidden_size, num_heads, num_layers=1, batch_first=False, proj_factor=4/3):\n",
    "         super(sLSTM, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.hidden_size = hidden_size\n",
    "         self.num_heads = num_heads\n",
    "         self.num_layers = num_layers\n",
    "         self.batch_first = batch_first\n",
    "         self.proj_factor_slstm = proj_factor\n",
    " \n",
    "         self.layers = nn.ModuleList([sLSTMBlock(input_size, hidden_size, num_heads, proj_factor) for _ in range(num_layers)])\n",
    " \n",
    "     def forward(self, x, state=None):\n",
    "         assert x.ndim == 3\n",
    "         if self.batch_first: x = x.transpose(0, 1)\n",
    "         seq_len, batch_size, _ = x.size()\n",
    "         \n",
    "         if state is not None:\n",
    "             state = torch.stack(list(state))\n",
    "             assert state.ndim == 4\n",
    "             num_hidden, state_num_layers, state_batch_size, state_input_size = state.size()\n",
    "             assert num_hidden == 4\n",
    "             assert state_num_layers == self.num_layers\n",
    "             assert state_batch_size == batch_size\n",
    "             assert state_input_size == self.input_size\n",
    "             state = state.transpose(0, 1)\n",
    "         else:\n",
    "             state = torch.zeros(self.num_layers, 4, batch_size, self.hidden_size)\n",
    " \n",
    "         output = []\n",
    "         for t in range(seq_len):\n",
    "             x_t = x[t]\n",
    "             for layer in range(self.num_layers):\n",
    "                 x_t, state_tuple = self.layers[layer](x_t, tuple(state[layer].clone()))\n",
    "                 state[layer] = torch.stack(list(state_tuple))\n",
    "             output.append(x_t)\n",
    "         \n",
    "         output = torch.stack(output)\n",
    "         if self.batch_first:\n",
    "             output = output.transpose(0, 1)\n",
    "         state = tuple(state.transpose(0, 1))\n",
    "         return output, state\n",
    " \n",
    "class mLSTMBlock(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_heads, proj_factor=2):\n",
    "         super(mLSTMBlock, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.hidden_size = hidden_size\n",
    "         self.num_heads = num_heads\n",
    "         self.head_size = hidden_size // num_heads\n",
    "         self.proj_factor = proj_factor\n",
    " \n",
    "         assert hidden_size % num_heads == 0\n",
    "         assert proj_factor > 0\n",
    "\n",
    "         self.layer_norm = nn.LayerNorm(input_size)\n",
    "         self.up_proj_left = nn.Linear(input_size, int(input_size * proj_factor))\n",
    "         self.up_proj_right = nn.Linear(input_size, hidden_size)\n",
    "         self.down_proj = nn.Linear(hidden_size, input_size)\n",
    " \n",
    "         self.causal_conv = CausalConv1D(1, 1, 4)\n",
    "         self.skip_connection = nn.Linear(int(input_size * proj_factor), hidden_size)\n",
    " \n",
    "         self.Wq = BlockDiagonal(int(input_size * proj_factor), hidden_size, num_heads)\n",
    "         self.Wk = BlockDiagonal(int(input_size * proj_factor), hidden_size, num_heads)\n",
    "         self.Wv = BlockDiagonal(int(input_size * proj_factor), hidden_size, num_heads)\n",
    "         self.Wi = nn.Linear(int(input_size * proj_factor), hidden_size)\n",
    "         self.Wf = nn.Linear(int(input_size * proj_factor), hidden_size)\n",
    "         self.Wo = nn.Linear(int(input_size * proj_factor), hidden_size)\n",
    " \n",
    "         self.group_norm = nn.GroupNorm(num_heads, hidden_size)\n",
    " \n",
    "     def forward(self, x, prev_state):\n",
    "         h_prev, c_prev, n_prev, m_prev = prev_state\n",
    "         assert x.size(-1) == self.input_size\n",
    "         x_norm = self.layer_norm(x)\n",
    "         x_up_left = self.up_proj_left(x_norm)\n",
    "         x_up_right = self.up_proj_right(x_norm)\n",
    " \n",
    "         x_conv = F.silu(self.causal_conv(x_up_left.unsqueeze(1)).squeeze(1))\n",
    "         x_skip = self.skip_connection(x_conv)\n",
    " \n",
    "         q = self.Wq(x_conv)\n",
    "         k = self.Wk(x_conv) / (self.head_size ** 0.5)\n",
    "         v = self.Wv(x_up_left)\n",
    " \n",
    "         i_tilde = self.Wi(x_conv)\n",
    "         f_tilde = self.Wf(x_conv)\n",
    "         o = torch.sigmoid(self.Wo(x_up_left))\n",
    " \n",
    "         m_t = torch.max(f_tilde + m_prev, i_tilde)\n",
    "         i = torch.exp(i_tilde - m_t)\n",
    "         f = torch.exp(f_tilde + m_prev - m_t)\n",
    " \n",
    "         c_t = f * c_prev + i * (v * k) # v @ k.T\n",
    "         n_t = f * n_prev + i * k\n",
    "         h_t = o * (c_t * q) / torch.max(torch.abs(n_t.T @ q), 1)[0] # o * (c @ q) / max{|n.T @ q|, 1}\n",
    " \n",
    "         output = h_t\n",
    "         output_norm = self.group_norm(output)\n",
    "         output = output_norm + x_skip\n",
    "         output = output * F.silu(x_up_right)\n",
    "         output = self.down_proj(output)\n",
    "         final_output = output + x\n",
    " \n",
    "         return final_output, (h_t, c_t, n_t, m_t)\n",
    "     \n",
    "class mLSTM(nn.Module):\n",
    "     # TODO: Add bias, dropout, bidirectional\n",
    "     def __init__(self, input_size, hidden_size, num_heads, num_layers=1, batch_first=False, proj_factor=2):\n",
    "         super(mLSTM, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.hidden_size = hidden_size\n",
    "         self.num_heads = num_heads\n",
    "         self.num_layers = num_layers\n",
    "         self.batch_first = batch_first\n",
    "         self.proj_factor_slstm = proj_factor\n",
    " \n",
    "         self.layers = nn.ModuleList([mLSTMBlock(input_size, hidden_size, num_heads, proj_factor) for _ in range(num_layers)])\n",
    " \n",
    "     def forward(self, x, state=None):\n",
    "         assert x.ndim == 3\n",
    "         if self.batch_first: x = x.transpose(0, 1)\n",
    "         seq_len, batch_size, _ = x.size()\n",
    "         \n",
    "         if state is not None:\n",
    "             state = torch.stack(list(state))\n",
    "             assert state.ndim == 4\n",
    "             num_hidden, state_num_layers, state_batch_size, state_input_size = state.size()\n",
    "             assert num_hidden == 4\n",
    "             assert state_num_layers == self.num_layers\n",
    "             assert state_batch_size == batch_size\n",
    "             assert state_input_size == self.input_size\n",
    "             state = state.transpose(0, 1)\n",
    "         else:\n",
    "             state = torch.zeros(self.num_layers, 4, batch_size, self.hidden_size)\n",
    " \n",
    "         output = []\n",
    "         for t in range(seq_len):\n",
    "             x_t = x[t]\n",
    "             for layer in range(self.num_layers):\n",
    "                 x_t, state_tuple = self.layers[layer](x_t, tuple(state[layer].clone()))\n",
    "                 state[layer] = torch.stack(list(state_tuple))\n",
    "             output.append(x_t)\n",
    "         \n",
    "         output = torch.stack(output)\n",
    "         if self.batch_first:\n",
    "             output = output.transpose(0, 1)\n",
    "         state = tuple(state.transpose(0, 1))\n",
    "         return output, state\n",
    " \n",
    "class xLSTM(nn.Module):\n",
    "     # TODO: Add bias, dropout, bidirectional\n",
    "     def __init__(self, input_size, hidden_size, num_heads, layers, batch_first=False, proj_factor_slstm=4/3, proj_factor_mlstm=2):\n",
    "         super(xLSTM, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.hidden_size = hidden_size\n",
    "         self.num_heads = num_heads\n",
    "         self.layers = layers\n",
    "         self.num_layers = len(layers)\n",
    "         self.batch_first = batch_first\n",
    "         self.proj_factor_slstm = proj_factor_slstm\n",
    "         self.proj_factor_mlstm = proj_factor_mlstm\n",
    " \n",
    "         self.layers = nn.ModuleList()\n",
    "         for layer_type in layers:\n",
    "             if layer_type == 's':\n",
    "                 layer = sLSTMBlock(input_size, hidden_size, num_heads, proj_factor_slstm)\n",
    "             elif layer_type == 'm':\n",
    "                 layer = mLSTMBlock(input_size, hidden_size, num_heads, proj_factor_mlstm)\n",
    "             else:\n",
    "                 raise ValueError(f\"Invalid layer type: {layer_type}. Choose 's' for sLSTM or 'm' for mLSTM.\")\n",
    "             self.layers.append(layer)\n",
    " \n",
    "     def forward(self, x, state=None):\n",
    "         assert x.ndim == 3\n",
    "         if self.batch_first: x = x.transpose(0, 1)\n",
    "         seq_len, batch_size, _ = x.size()\n",
    "         \n",
    "         if state is not None:\n",
    "             state = torch.stack(list(state))\n",
    "             assert state.ndim == 4\n",
    "             num_hidden, state_num_layers, state_batch_size, state_input_size = state.size()\n",
    "             assert num_hidden == 4\n",
    "             assert state_num_layers == self.num_layers\n",
    "             assert state_batch_size == batch_size\n",
    "             assert state_input_size == self.input_size\n",
    "             state = state.transpose(0, 1)\n",
    "         else:\n",
    "             state = torch.zeros(self.num_layers, 4, batch_size, self.hidden_size)\n",
    " \n",
    "         output = []\n",
    "         for t in range(seq_len):\n",
    "             x_t = x[t]\n",
    "             for layer in range(self.num_layers):\n",
    "                 x_t, state_tuple = self.layers[layer](x_t, tuple(state[layer].clone()))\n",
    "                 state[layer] = torch.stack(list(state_tuple))\n",
    "             output.append(x_t)\n",
    "         \n",
    "         output = torch.stack(output)\n",
    "         if self.batch_first:\n",
    "             output = output.transpose(0, 1)\n",
    "\n",
    "         state = tuple(state.transpose(0, 1))\n",
    "         \n",
    "         return output, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditsxLSTM(nn.Module):\n",
    "    def __init__(self, features, embedding_projections, hidden_size=258, num_heads=6, layers=['s', 'm', 's'], proj_factor_slstm=4/3, proj_factor_mlstm=2):\n",
    "        super(CreditsxLSTM, self).__init__()\n",
    "        self.embedding_projections = nn.ModuleList([self._create_embedding_projection(*embedding_projections[feature]) for feature in features])\n",
    "        self.input_size = sum([embedding_projections[feature][1] for feature in features])\n",
    "        self.xlstm = xLSTM(input_size=self.input_size, hidden_size=hidden_size, num_heads=num_heads, layers=layers, proj_factor_slstm=proj_factor_slstm, proj_factor_mlstm=proj_factor_mlstm, batch_first=True)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.top_classifier = nn.Linear(hidden_size, 32)\n",
    "        self.intermediate_activation = nn.ReLU()\n",
    "        self.head = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, features):\n",
    "        device = next(self.parameters()).device  # Get the device of the model's parameters\n",
    "        batch_size = features[0].shape[0]\n",
    "        \n",
    "        # Ensure features are on the same device as the model\n",
    "        embeddings = [embedding(features[i].to(device)) for i, embedding in enumerate(self.embedding_projections)]\n",
    "        concated_embeddings = torch.cat(embeddings, dim=-1)\n",
    "\n",
    "        output, last_hidden = self.xlstm(concated_embeddings)\n",
    "        last_hidden_mean = torch.mean(last_hidden[-1], dim=0, keepdim=True)\n",
    "\n",
    "        last_hidden_mean = torch.reshape(last_hidden_mean.permute(1, 2, 0), shape=(batch_size, self.hidden_size))\n",
    "        \n",
    "        classification_hidden = self.top_classifier(last_hidden_mean)\n",
    "        activation = self.intermediate_activation(classification_hidden)\n",
    "        raw_output = self.head(activation)\n",
    "        \n",
    "        return raw_output\n",
    "\n",
    "    @classmethod\n",
    "    def _create_embedding_projection(cls, cardinality, embed_size, add_missing=True, padding_idx=0):\n",
    "        add_missing = 1 if add_missing else 0\n",
    "        return nn.Embedding(num_embeddings=cardinality + add_missing, embedding_dim=embed_size, padding_idx=padding_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = CreditsxLSTM(features, embedding_projections)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, optimizer: torch.optim.Optimizer, dataset_train: List[str],\n",
    "                batch_size: int = 64, shuffle: bool = True, print_loss_every_n_batches: int = 500,\n",
    "                device: torch.device = None):\n",
    "\n",
    "    model.train()\n",
    "    loss_function = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    losses = torch.Tensor().to(device)\n",
    "    samples_counter = 0\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle, device=device, is_train=True, output_format=\"torch\")\n",
    "\n",
    "    for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n",
    "        # Ensure the model, features, and labels are on the same device\n",
    "        features = [feature.to(device) for feature in batch[\"features\"]]\n",
    "        labels = batch[\"label\"].float().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = torch.flatten(model(features))\n",
    "\n",
    "        # Compute loss\n",
    "        batch_loss = loss_function(output.to(device), labels.to(device))\n",
    "        batch_loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        samples_counter += batch_loss.size(0)\n",
    "\n",
    "        losses = torch.cat([losses, batch_loss], dim=0)\n",
    "        if num_batch % print_loss_every_n_batches == 0:\n",
    "            print(f\"Batches {num_batch - print_loss_every_n_batches + 1} - {num_batch} loss:\"\n",
    "                  f\"{losses[-samples_counter:].mean().item()}\", end=\"\\r\")\n",
    "            samples_counter = 0\n",
    "        if num_batch % 10 == 0:\n",
    "            print(\"Batch: \", num_batch)\n",
    "\n",
    "        if num_batch == 780:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673e216a155147919a53a17bf9f612e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.1266031712293625\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b92e45e1bf74f8690aaf9692f1a7135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Validation ROC AUC: 0.6633\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba142be62084713b009c3593e5d0573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.18795642256736755\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ad1658dd264c0386e832dbe1737c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Validation ROC AUC: 0.7291\n",
      "Starting epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81642fb6b74742738c303125f7ad81c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.11287154257297516\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fe92915dee4c879795910dcc28b579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Validation ROC AUC: 0.7223\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cd4292a8e2474eb9ea01162dcd5507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.12739212810993195\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850a52017892493eb4602a12caf40653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Validation ROC AUC: 0.7499\n",
      "Starting epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5131f20df4354aa4aa1322c278419b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.14468777179718018\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3ce3f0e2aa4584b2ad5ba4ae5cd8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Validation ROC AUC: 0.7454\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5870b6250f24e78a8449b805031c1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Epoch 6 completed. Validation ROC AUC: 0.7364\n",
      "Starting epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a0a2a6afe84d30a8519da892ad5a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.11975815892219543\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaa06f69a5e4c28b02c40a347d4a564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Validation ROC AUC: 0.7603\n",
      "Starting epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee5e7572a224b3fa476f1920f4d8c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581e44d8733d4f24ae1815d2d38a49ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Validation ROC AUC: 0.7543\n",
      "Starting epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f30189f3d94fb9b18eeea038e9b57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.13187247514724731\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1bbc04fb8c430d87984c55973924b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Validation ROC AUC: 0.7444\n",
      "Starting epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480959/909155273.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7768571abe64a979314b3c9e8927a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  10\n",
      "Batch:  20\n",
      "Batch:  30\n",
      "Batch:  40\n",
      "Batch:  50\n",
      "Batch:  60\n",
      "Batch:  70\n",
      "Batch:  80\n",
      "Batch:  90\n",
      "Batch:  100\n",
      "Batch:  110\n",
      "Batch:  120\n",
      "Batch:  130\n",
      "Batch:  140\n",
      "Batch:  150\n",
      "Batch:  160\n",
      "Batch:  170\n",
      "Batch:  180\n",
      "Batch:  190\n",
      "Batch:  200\n",
      "Batch:  210\n",
      "Batch:  220\n",
      "Batch:  230\n",
      "Batch:  240\n",
      "Batch:  250\n",
      "Batch:  260\n",
      "Batch:  270\n",
      "Batch:  280\n",
      "Batch:  290\n",
      "Batch:  300\n",
      "Batch:  310\n",
      "Batch:  320\n",
      "Batch:  330\n",
      "Batch:  340\n",
      "Batch:  350\n",
      "Batch:  360\n",
      "Batch:  370\n",
      "Batch:  380\n",
      "Batch:  390\n",
      "Batch:  400\n",
      "Batch:  410\n",
      "Batch:  420\n",
      "Batch:  430\n",
      "Batch:  440\n",
      "Batch:  450\n",
      "Batch:  460\n",
      "Batch:  470\n",
      "Batch:  480\n",
      "Batch:  490\n",
      "Batch:  500 500 loss:0.12298358976840973\n",
      "Batch:  510\n",
      "Batch:  520\n",
      "Batch:  530\n",
      "Batch:  540\n",
      "Batch:  550\n",
      "Batch:  560\n",
      "Batch:  570\n",
      "Batch:  580\n",
      "Batch:  590\n",
      "Batch:  600\n",
      "Batch:  610\n",
      "Batch:  620\n",
      "Batch:  630\n",
      "Batch:  640\n",
      "Batch:  650\n",
      "Batch:  660\n",
      "Batch:  670\n",
      "Batch:  680\n",
      "Batch:  690\n",
      "Batch:  700\n",
      "Batch:  710\n",
      "Batch:  720\n",
      "Batch:  730\n",
      "Batch:  740\n",
      "Batch:  750\n",
      "Batch:  760\n",
      "Batch:  770\n",
      "Batch:  780\n",
      "Next step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946104c7a63f4d18b2d9035417cd7a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}\")\n",
    "    train_epoch(model, optimizer, dataset_train, batch_size=train_batch_size, \n",
    "                shuffle=True, print_loss_every_n_batches=500, device=device)\n",
    "\n",
    "    print(\"Next step\")\n",
    "\n",
    "    \n",
    "    # Оценка модели на валидационных данных\n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_size, device=device)\n",
    "    \n",
    "    # Сохранение модели по результатам валидации\n",
    "    torch.save(model.state_dict(), f\"epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt\")\n",
    "    print(f\"Epoch {epoch+1} completed. Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r .../main_project/./checkpoints/\n",
    "!mkdir .../main_project/./checkpoints/\n",
    "\n",
    "!rm -r .../main_project/./checkpoints/pytorch_baseline\n",
    "!mkdir .../main_project/./checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для того, чтобы детектировать переобучение используем EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_checkpoints = \"/trinity/home/team08/workspace/data/./checkpoints/pytorch_baseline/\"\n",
    "es = EarlyStopping(patience=3, mode=\"max\", verbose=True, save_path=os.path.join(path_to_checkpoints, \"best_checkpoint.pt\"), \n",
    "                   metric_name=\"ROC-AUC\", save_format=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"Starting epoch {epoch+1}\")\n",
    "#     train_epoch(model, optimizer, dataset_train, batch_size=train_batch_size, \n",
    "#                 shuffle=True, print_loss_every_n_batches=500, device=device)\n",
    "    \n",
    "#     val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_size, device=device)\n",
    "#     es(val_roc_auc, model)\n",
    "    \n",
    "#     if es.early_stop:\n",
    "#         print(\"Early stopping reached. Stop training...\")\n",
    "#         break\n",
    "#     torch.save(model.state_dict(), os.path.join(path_to_checkpoints, f\"epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt\"))\n",
    "    \n",
    "#     train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_size, device=device)\n",
    "#     print(f\"Epoch {epoch+1} completed. Train ROC AUC: {train_roc_auc}, val ROC AUC: {val_roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Подготовим посылку в проверяющую систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# path_to_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, \"best_checkpoint.pt\"), map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, \"best_checkpoint.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds = inference(model, dataset_test, batch_size=128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_preds = inference(model, dataset_train, batch_size=128, device=device)\n",
    "# train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(train_preds.score, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_preds.score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_target[:2700000].flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CreditsxLSTM(nn.Module):\n",
    "#     def __init__(self, features, embedding_projections, hidden_size=258, num_heads=6, layers=['s', 'm', 's'], proj_factor_slstm=4/3, proj_factor_mlstm=2):\n",
    "#         super(CreditsxLSTM, self).__init__()\n",
    "#         self.embedding_projections = nn.ModuleList([self._create_embedding_projection(*embedding_projections[feature]) for feature in features])\n",
    "#         self.input_size = sum([embedding_projections[feature][1] for feature in features])\n",
    "#         print(self.input_size)\n",
    "#         self.xlstm = xLSTM(input_size=self.input_size, hidden_size=hidden_size, num_heads=num_heads, layers=layers, proj_factor_slstm=proj_factor_slstm, proj_factor_mlstm=proj_factor_mlstm, batch_first=True)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.top_classifier = nn.Linear(hidden_size, 32)\n",
    "#         self.intermediate_activation = nn.ReLU()\n",
    "#         self.head = nn.Linear(32, 1)\n",
    "\n",
    "#     def forward(self, features):\n",
    "#         batch_size = features[0].shape[0]\n",
    "#         embeddings = [embedding(features[i]) for i, embedding in enumerate(self.embedding_projections)]\n",
    "#         concated_embeddings = torch.cat(embeddings, dim=-1)\n",
    "\n",
    "\n",
    "#         output, last_hidden = self.xlstm(concated_embeddings)\n",
    "#         #last_hidden = state[-1]\n",
    "#         #last_hidden = last_hidden[0]\n",
    "\n",
    "\n",
    "#         last_hidden_mean = torch.mean(last_hidden[-1], dim=0, keepdim=True)  # Теперь last_hidden_mean имеет размерность (1, 128, 258)\n",
    "\n",
    "\n",
    "        \n",
    "#         last_hidden_mean = torch.reshape(last_hidden_mean.permute(1, 2, 0), shape=(batch_size, self.hidden_size))\n",
    "        \n",
    "#         classification_hidden = self.top_classifier(last_hidden_mean)\n",
    "#         activation = self.intermediate_activation(classification_hidden)\n",
    "#         raw_output = self.head(activation)\n",
    "#         return raw_output\n",
    "\n",
    "#     @classmethod\n",
    "#     def _create_embedding_projection(cls, cardinality, embed_size, add_missing=True, padding_idx=0):\n",
    "#         add_missing = 1 if add_missing else 0\n",
    "#         return nn.Embedding(num_embeddings=cardinality + add_missing, embedding_dim=embed_size, padding_idx=padding_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
